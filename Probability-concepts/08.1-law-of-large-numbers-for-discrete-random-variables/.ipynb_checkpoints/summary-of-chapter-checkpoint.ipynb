{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Chebyshev Inequality*\n",
    "\n",
    "# Theorem 8.1\n",
    "\n",
    "### Let $X$ be a discrete random variable with expected value $\\mu$ and let $\\epsilon>0$ be any positive real number\n",
    "\n",
    "### Then\n",
    "\n",
    "# $P(|X-\\mu|\\geq \\epsilon) \\leq \\frac{V(X)}{\\epsilon^{2}}$\n",
    "\n",
    "## *Proof*\n",
    "\n",
    "# $V(X) = \\sum_{x}(x-\\mu)^{2}m(x) \\geq \\sum_{|x-\\mu|\\geq \\epsilon}(x-\\mu)^{2}m(x)\\geq \\sum_{|x-\\mu|\\geq \\epsilon}(\\epsilon)^{2}m(x)$\n",
    "\n",
    "# $= \\epsilon^{2}\\sum_{|x-\\mu|\\geq \\epsilon}m(x) = \\epsilon^{2}P(|X-\\mu|\\geq \\epsilon)$\n",
    "\n",
    "\n",
    "# Therefore $V(X)\\geq \\epsilon^{2}P(|X-\\mu|\\geq \\epsilon) \\implies P(|X-\\mu|\\geq \\epsilon)\\leq \\frac{V(X)}{\\epsilon^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### If we let $\\epsilon = \\sigma$, then $P(|X-\\mu|\\geq \\sigma)\\leq \\frac{V(X)}{\\sigma^{2}} = 1$ (this doesn't really tell us anything)\n",
    "\n",
    "### If we let $\\epsilon = 2\\sigma$, then $P(|X-\\mu|\\geq 2\\sigma)\\leq \\frac{V(X)}{4\\sigma^{2}} = \\frac{1}{4}$ (this means that the probability that a random $X$ value will be at least 2 standard deviations away from the mean is less than 0.25 i.e. fewer than 25% of random $X$ values will be in the outer zone)\n",
    "\n",
    "\n",
    "### If we let $\\epsilon = k\\sigma$, then $P(|X-\\mu|\\geq 2\\sigma)\\leq \\frac{V(X)}{4\\sigma^{2}} = \\frac{1}{k^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Why is Chebyshev's Inequality Important?*\n",
    "\n",
    "- It's a pretty crude inequality\n",
    "    - However, it is true for all random variables\n",
    "        - Very handy in proofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# *Law of Large Numbers*\n",
    "\n",
    "# Theorem 8.2\n",
    "\n",
    "### Let $X_{1}$, $X_{2}$, ..., $X_{n}$ be a independent trials process each with expected value $\\mu$ and variance $\\sigma^{2}$\n",
    "\n",
    "### Let $S_{n} = X_{1}+X_{2}+...+X_{n}$ and $A_{n} = \\frac{S_{n}}{n}$\n",
    "\n",
    "### Then, for any $\\epsilon > 0$\n",
    "\n",
    "# $P(|A_{n}-\\mu| > \\epsilon)\\rightarrow 0 \\text{ as } n\\rightarrow \\infty$\n",
    "\n",
    "# *What does this mean?*\n",
    "\n",
    "### As we take bigger and bigger samples, our average value gets closer and closer to $\\mu$\n",
    "\n",
    "# AGAIN: the Law of Large Numbers says that if we repeat an experiment many times, we'll get the result we expect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "____\n",
    "\n",
    "## Example\n",
    "\n",
    "### Let $X_{1}$, $X_{2}$, ..., $X_{n}$ be a Bernoulli trials process with $p=0.3 \\implies q=0.7$\n",
    "\n",
    "### We know $E(X_{i}) = p = 0.3$ and $V(X) = pq = (0.3)(0.7) = 0.21$\n",
    "\n",
    "### If we define $A_{n} = \\frac{S_{n}}{n} = \\frac{X_{1}+X_{2}+...+X_{n}}{n}$ then $E(A_{n}) = \\frac{1}{n} np = p = 0.3$ and $V(A_{n}) = \\frac{1}{n^{2}}npq = \\frac{pq}{n} = \\frac{0.21}{n}$\n",
    "\n",
    "### Then, applying Chebyshev's theorem, $P(|A_{n}-0.3|>\\epsilon) \\leq \\frac{0.21}{n\\epsilon^{2}}$\n",
    "\n",
    "### So, if out trials process has $n=100$ then $V(A_{n}) = 0.0021$ so the probability that the observed $A_{n}$ value is greater than 0.1 away from 0.3 is less than $\\frac{0.0021}{0.1^{2}} = 0.21$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
